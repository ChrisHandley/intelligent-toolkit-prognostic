{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "scoring_function = [1877.612, 2030.918, 1912.785481, 1672.520841, 2050.989301, 2477.963,\n",
    "                   1540.401395, 1433.541178, 1147.4, 999.5, 890.2, 957.3,1221.4] ## Metrics\n",
    "training_time = [20.011164, 0.209155, 9.211304,37.020665,32.794138,0.029446,13.334237, \n",
    "                 1.267747,402,2625 ,262 , 1725,1051] ## SAVINGS OF A PROCESS\n",
    "r2 = np.array([0.622, 0.553,0.586,0.609,0.530, 0.464,0.621,0.559,0.34, 0.61, 0.78,  0.67, 0.72])*10\n",
    "r2 = r2.tolist()\n",
    "approach = ['SVR', 'KNN', 'XGB', 'RF', 'Adaboost', 'SGD', 'ET', 'bagging', 'LSTM', 'GRU', 'CNN_1d',\n",
    "           'CNN_2d', 'MLP']\n",
    "dd_type = ['ML','ML','ML','ML','ML','ML','ML','ML','DL','DL','DL','DL','DL']\n",
    "\n",
    "sf_vs_tt = pd.DataFrame({\"Scoring Function\": scoring_function, \"Training Time\" : training_time,\n",
    "                         \"Approach\": approach, \"R2\":r2,\"Type\": dd_type})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_vs_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#sns.scatterplot(x=\"tt\", y=\"sf\", hue=\"time\",data=sf_vs_tt_lf)\n",
    "# Load the example iris dataset\n",
    "#diamonds = sns.load_dataset(\"diamonds\")\n",
    "\n",
    "# Draw a scatter plot while assigning point colors and sizes to different\n",
    "# variables in the dataset\n",
    "\n",
    "f, ax = plt.subplots(figsize=(11, 11))\n",
    "ax = sns.scatterplot(x=\"Scoring Function\",y=\"Training Time\",hue=\"Approach\",\n",
    "                     data=sf_vs_tt,s=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "plt.figure(figsize=(10,10))\n",
    "svr = plt.scatter(1877.612, 20.011164, marker='o', color=colors[0])\n",
    "knn = plt.scatter(2030.918, 0.209155, marker='o', color=colors[1])\n",
    "xgb  = plt.scatter(1912.785481, 9.211304, marker='o', color=colors[2])\n",
    "rf  = plt.scatter(1672.520841, 37.020665, marker='o', color=colors[3])\n",
    "# dt  = plt.scatter(7.795658e+06, 0.399910, marker='o', color=colors[3])\n",
    "adb = plt.scatter(2050.989301, 32.794138, marker='o', color=colors[4])\n",
    "sgd = plt.scatter(2477.963,0.029446, marker='o', color=colors[5])\n",
    "et = plt.scatter(1540.401395,13.334237, marker='o', color=colors[6])\n",
    "bag = plt.scatter(1433.541178, 1.267747, marker='x', color=colors[7])\n",
    "\n",
    "lstm = plt.scatter(1147.4, 402, marker='x', color=colors[1])\n",
    "gru = plt.scatter(999.5,2625 , marker='x', color=colors[2])\n",
    "cnn_1d = plt.scatter(890.2, 262 , marker='x', color=colors[3])\n",
    "cnn_2d = plt.scatter(957.3, 1725, marker='x', color=colors[4])\n",
    "cnn = plt.scatter(2552.214, 2743.92, marker='x', color=colors[5])\n",
    "mlp = plt.scatter(1221.4, 1051, marker='x', color=colors[6])\n",
    "\n",
    "plt.title('Scoring Function vs Training Time')\n",
    "plt.ylabel('Time(s)')\n",
    "plt.xlabel('Scoring Function')\n",
    "\n",
    "plt.legend((svr, knn, xgb, rf, adb, sgd, et, bag, lstm, gru, cnn_1d, cnn_2d, cnn, mlp),\n",
    "           ('SVR', 'KNN', 'XGB', 'RF', 'Adaboost', 'SGD', 'ET', 'bagging', 'LSTM', 'GRU', 'CNN_1d',\n",
    "           'CNN_2d', 'CNN', 'MLP'),\n",
    "           scatterpoints=1,\n",
    "           loc='upper right',\n",
    "           ncol=3,\n",
    "           fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modelname(model):\n",
    "    name = str(model).partition('(')[0]\n",
    "    if name=='SVR':\n",
    "        name = model.get_params()['kernel'] + name\n",
    "    return(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evalModels(models, Xw, y, boxPlotOn=True):\n",
    "#     from sklearn.preprocessing import StandardScaler # Standardize data (0 mean, 1 stdev)\n",
    "#     from sklearn.model_selection import KFold\n",
    "#     from sklearn.model_selection import cross_val_score\n",
    "#     from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "#     scoring = 'neg_mean_absolute_error'  \n",
    "\n",
    "#     modelnames = []\n",
    "#     results = []\n",
    "#     for model in models:\n",
    "#         pipe = make_pipeline( StandardScaler(), model )\n",
    "#         kfold = KFold(n_splits=10, shuffle=False)\n",
    "#         cv_results = cross_val_score(pipe, Xw, y, cv=kfold, scoring=scoring)\n",
    "#         modelname = get_modelname(model)\n",
    "#         print(\"%s: %.3f %.3f\" %(modelname, -1*cv_results.mean(), cv_results.std()))\n",
    "#         modelnames.append(modelname)\n",
    "#         results.append(-1*cv_results)\n",
    "\n",
    "        \n",
    "#     if boxPlotOn:\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         # boxplot algorithm comparison\n",
    "#         fig = plt.figure()\n",
    "#         fig.suptitle('Algorithm Comparison')\n",
    "#         ax = fig.add_subplot(111)\n",
    "#         plt.boxplot(results, showmeans=True)\n",
    "#         ax.set_xticklabels(modelnames, fontsize=9)\n",
    "#         plt.xticks(rotation=90)\n",
    "#         plt.show()\n",
    "    \n",
    "#     return(results, modelnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "def prepros(train_file, test_file, ground_file):\n",
    "    # read training data - It is the aircraft engine run-to-failure data.\n",
    "    train_df = pd.read_csv(train_file, sep=\" \", header=None)\n",
    "\n",
    "    #remove the columns 26 and 27 because of NAN values\n",
    "    train_df=train_df.loc[:,0:25]\n",
    "\n",
    "    train_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                         's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                         's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "\n",
    "    train_df = train_df.sort_values(['id','cycle'])\n",
    "\n",
    "    # read test data - It is the aircraft engine operating data without failure events recorded.\n",
    "    test_df = pd.read_csv(test_file, sep=\" \", header=None)\n",
    "\n",
    "    #remove the columns 26 and 27 because of NAN values\n",
    "    test_df=test_df.loc[:,0:25]\n",
    "\n",
    "    test_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                         's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                         's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "\n",
    "    test_df = test_df.sort_values(['id','cycle'])\n",
    "\n",
    "    #read ground truth data - It contains the information of true remaining cycles for each engine in the testing data.\n",
    "    truth_df = pd.read_csv(ground_file, sep=\" \", header=None)\n",
    "\n",
    "    #remove the columns 1 because of NAN values\n",
    "    truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)\n",
    "    truth_df.columns = ['cycle']\n",
    "\n",
    "    # Data Labeling - generate column RUL(Remaining Usefull Life or Time to Failure)\n",
    "    ##TRAINING DATASET\n",
    "    rul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\n",
    "    rul.columns = ['id', 'max']\n",
    "\n",
    "    train_df = train_df.merge(rul, on=['id'], how='left')\n",
    "\n",
    "    train_df['RUL'] = train_df['max'] - train_df['cycle']\n",
    "    train_df.drop('max', axis=1, inplace=True)\n",
    "\n",
    "    # generate label columns for training data\n",
    "    # we will only make use of \"label1\" for binary classification, \n",
    "    # while trying to answer the question: is a specific engine going to fail within w1 cycles?\n",
    "    w1 = 30\n",
    "    w0 = 15\n",
    "    train_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\n",
    "\n",
    "    train_df['label2'] = train_df['label1']\n",
    "    train_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\n",
    "\n",
    "    #check columns with repeated values: setting3, s1, s5, s10, s16,s18,s19\n",
    "    train_df.apply(lambda x: x.nunique())\n",
    "    train_df.drop(train_df.columns[[4,5,9,14,20,22,23]], axis=1, inplace=True)\n",
    "\n",
    "    #TEST DATASET\n",
    "    test_df.drop(test_df.columns[[4,5,9,14,20,22,23]], axis=1, inplace=True)\n",
    "    test_df.apply(lambda x: x.nunique())\n",
    "\n",
    "    # We use the ground truth dataset to generate labels for the test data.\n",
    "    # generate column max for test data\n",
    "    rul = pd.DataFrame(test_df.groupby('id')['cycle'].max()).reset_index()\n",
    "\n",
    "    rul.columns = ['id', 'max']\n",
    "    truth_df.columns = ['more']\n",
    "    truth_df['id'] = truth_df.index + 1\n",
    "    truth_df['max'] = rul['max'] + truth_df['more']\n",
    "    truth_df.drop('more', axis=1, inplace=True)\n",
    "\n",
    "    # generate RUL for test data\n",
    "    test_df = test_df.merge(truth_df, on=['id'], how='left')\n",
    "    test_df['RUL'] = test_df['max'] - test_df['cycle']\n",
    "    test_df.drop('max', axis=1, inplace=True)\n",
    "\n",
    "    # generate label columns w0 and w1 for test data\n",
    "    test_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\n",
    "    test_df['label2'] = test_df['label1']\n",
    "    test_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\n",
    "\n",
    "    # MinMax normalization (from 0 to 1)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    ###TRAIN#####\n",
    "    train_df['cycle_norm'] = train_df['cycle']\n",
    "    cols_normalize = train_df.columns.difference(['id','cycle','RUL','label1','label2'])\n",
    "    norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n",
    "                                 columns=cols_normalize, \n",
    "                                 index=train_df.index)\n",
    "\n",
    "    join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
    "    train_df = join_df.reindex(columns = train_df.columns)\n",
    "\n",
    "    ####TEST#####\n",
    "    test_df['cycle_norm'] = test_df['cycle']\n",
    "    test_df['id_norm'] = test_df['id']\n",
    "    norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n",
    "                                columns=cols_normalize, \n",
    "                                index=test_df.index)\n",
    "    test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
    "    test_df = test_join_df.reindex(columns = test_df.columns)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    #### Generating input data\n",
    "    # pick the feature columns \n",
    "    sequence_cols = train_df.columns.difference(['id','cycle','RUL','label1','label2'])\n",
    "\n",
    "    # generate sequences and convert to numpy array\n",
    "    X_train = train_df[sequence_cols]\n",
    "\n",
    "    #obtain the last cycle data for each test battery\n",
    "    test_df=test_df.loc[test_df.groupby('id').cycle.idxmax()]\n",
    "    X_test = test_df[sequence_cols]\n",
    "    # Generate labels\n",
    "    y_train=train_df['RUL']\n",
    "    y_test=test_df['RUL']\n",
    "    return (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divishrengasamy/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "X_train_1, y_train_1, X_test_1, y_test_1 = prepros('train_FD001.txt', 'test_FD001.txt', 'RUL_FD001.txt')\n",
    "# X_train_2, y_train_2, X_test_2, y_test_2 = prepros('train_FD002.txt', 'test_FD002.txt', 'RUL_FD002.txt')\n",
    "# X_train_3, y_train_3, X_test_3, y_test_3 = prepros('train_FD003.txt', 'test_FD003.txt', 'RUL_FD003.txt')\n",
    "# X_train_4, y_train_4, X_test_4, y_test_4 = prepros('train_FD004.txt', 'test_FD004.txt', 'RUL_FD004.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modelname(model):\n",
    "    name = str(model).partition('(')[0]\n",
    "    if name=='SVR':\n",
    "        name = model.get_params()['kernel'] + name\n",
    "    return(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_function(true, pred):\n",
    "        d = pred - true\n",
    "        length = len(d)\n",
    "        s = 0\n",
    "        for i in range(length):\n",
    "            if (d[i] < 0):\n",
    "                s += np.exp((-d[i]/10))-1\n",
    "            else:\n",
    "                s += np.exp((d[i]/13))-1\n",
    "        timeliness_value.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true, pred):\n",
    "    d_squared = (pred - true)**2\n",
    "    err = np.mean(d_squared)\n",
    "    err = np.sqrt(err)\n",
    "    rmse_value.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(true,pred):\n",
    "    d=abs(pred - true)\n",
    "    err=np.mean(d)\n",
    "    mae_value.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae(true, pred):\n",
    "    d=abs(pred-true)\n",
    "    ae_value.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re(true, pred):\n",
    "    d = (abs(pred-true)/true)\n",
    "    re_value.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def me(true, pred):\n",
    "    d=(sum(abs(pred-true))/len(pred))\n",
    "    me_value.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(true, pred):\n",
    "    err = 100/len(true) * np.sum(2 * np.abs(pred - true) / (np.abs(true) + np.abs(pred)))\n",
    "    smape_value.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_results(d):\n",
    "    df = pd.DataFrame(data=d)\n",
    "    df.set_index('Model', inplace=True)\n",
    "    df.index.name='Model'\n",
    "    print(df)\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def evalModels(models, X_train, y_train, X_test, y_test, boxPlotOn=True):\n",
    "    from sklearn.preprocessing import StandardScaler # Standardize data (0 mean, 1 stdev)\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.pipeline import Pipeline, make_pipeline\n",
    "    from sklearn.metrics import r2_score\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    scoring = 'neg_mean_absolute_error'  \n",
    "\n",
    "    modelnames = []\n",
    "    fitted_models = []\n",
    "    results = []\n",
    "    training_time = []\n",
    "    testing_time = []\n",
    "    predicted_value = []\n",
    "    timeliness_value = []\n",
    "    rmse_value = []\n",
    "    mae_value = []\n",
    "    smape_value = []\n",
    "    r2_value = []\n",
    "    ae_value = []\n",
    "    re_value = []\n",
    "    me_value = []\n",
    "    for model in models:\n",
    "        pipe = make_pipeline( StandardScaler(), model )\n",
    "        kfold = KFold(n_splits=10, shuffle=False)\n",
    "        cv_results = cross_val_score(pipe, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        modelname = get_modelname(model)\n",
    "        print(\"%s: %.3f %.3f\" %(modelname, -1*cv_results.mean(), cv_results.std()))\n",
    "        modelnames.append(modelname)\n",
    "        results.append(-1*cv_results)\n",
    "        \n",
    "    \n",
    "    for model in models:\n",
    "        start = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        end = time.time()\n",
    "        train_time = end - start\n",
    "        fitted_models.append(model)\n",
    "        training_time.append(train_time)\n",
    "        \n",
    "    \n",
    "    for fittedmodels in fitted_models:\n",
    "        start = time.time()\n",
    "        y_pred = fittedmodels.predict(X_test)\n",
    "        end = time.time()\n",
    "        test_time = end - start\n",
    "        testing_time.append(test_time)\n",
    "        scoring_function(y_test.values, y_pred)\n",
    "        rmse(y_test.values, y_pred)\n",
    "        ae(y_test.values, y_pred)\n",
    "        mae(y_test.values, y_pred)\n",
    "        smape(y_test.values, y_pred)\n",
    "        r2_value.append(r2_score(y_test.values, y_pred))\n",
    "        predicted_value.append(y_pred)\n",
    "\n",
    "        \n",
    "    if boxPlotOn:\n",
    "        fig = plt.figure()\n",
    "        sns.boxplot(data=results)\n",
    "        plt.xticks(plt.xticks()[0], modelnames)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel('Mean Absolute Error')\n",
    "        fig.savefig('boxplot.png')\n",
    "        \n",
    "    data = {'Model':modelnames,'Scoring Function': timeliness_value, 'RMSE': rmse_value,'R^2':r2_value, 'MAE':mae_value,'SMAPE':smape_value, 'Training Time': training_time, 'Testing Time': testing_time}\n",
    "    final_results(data)\n",
    "    return(results,\n",
    "           predicted_value,\n",
    "           testing_time,\n",
    "           timeliness_value,\n",
    "           rmse_value,\n",
    "           mae_value,\n",
    "           smape_value,\n",
    "           r2_value,\n",
    "           modelnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor: 34.550 9.654\n",
      "KNeighborsRegressor: 27.550 7.980\n",
      "                     Scoring Function       RMSE       R^2        MAE  \\\n",
      "Model                                                                   \n",
      "SGDRegressor              2477.963462  30.402627  0.464743  25.202195   \n",
      "KNeighborsRegressor       2030.918125  27.756575  0.553859  20.731514   \n",
      "\n",
      "                         SMAPE  Training Time  Testing Time  \n",
      "Model                                                        \n",
      "SGDRegressor         40.650551       0.037348      0.001045  \n",
      "KNeighborsRegressor  26.511669       0.329058      0.054739  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAFdCAYAAAAOkmpzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor, BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn import neighbors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# create and evaluate pipeline\n",
    "models = []\n",
    "models.append( SGDRegressor(shuffle=False, max_iter=None, tol=None, alpha=1.0,\n",
    "                            loss='squared_loss', penalty='l1') )\n",
    "models.append( ExtraTreesRegressor(max_features='sqrt',\n",
    "                                 min_samples_leaf=1,\n",
    "                                 min_samples_split=10,\n",
    "                                 n_estimators=700,\n",
    "                                 verbose=1))\n",
    "models.append( AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), \n",
    "                                 learning_rate=0.01,\n",
    "                                 loss='exponential',\n",
    "                                 n_estimators=400) )\n",
    "models.append( BaggingRegressor(n_estimators=400,\n",
    "                                bootstrap=True, \n",
    "                                max_features=18,\n",
    "                                max_samples=30) )\n",
    "models.append( RandomForestRegressor(max_features='sqrt',\n",
    "                                     min_samples_leaf=4,\n",
    "                                     min_samples_split=10,\n",
    "                                     n_estimators=800,\n",
    "                                     verbose=1) )\n",
    "models.append( svm.SVR(C=1,\n",
    "                       epsilon=0.1,\n",
    "                       kernel='rbf',\n",
    "                       gamma='scale') )\n",
    "models.append( xgb.XGBRegressor(objective=\"reg:linear\",\n",
    "                                n_estimators=500,\n",
    "                                nthread=-1,\n",
    "                                silent=False,\n",
    "                                colsample_bytree=0.7,\n",
    "                                gamma=0.5,\n",
    "                                min_child_weight=1,\n",
    "                                subsample=1.0) )\n",
    "models.append( neighbors.KNeighborsRegressor(algorithm='auto', \n",
    "                                             n_neighbors=40,\n",
    "                                             weights='distance') )\n",
    "\n",
    "results, predicted_value, testing_time,timeliness,rmse,mae,smape,r2,modelnames = evalModels(models,X_train_1,y_train_1,X_test_1,y_test_1,boxPlotOn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "fig = plt.figure()\n",
    "sns.boxplot(data=results)\n",
    "plt.xticks(plt.xticks()[0], modelnames)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "fig.savefig('boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.boxplot(data=results)\n",
    "plt.xticks(plt.xticks()[0], modelnames)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = results[0:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test.append(np.array([18.01777016124075, 19.08547714234841, 18.61810288177123, 17.619403154163166, 17.469617410877248, 18.34671841387774, 17.442145677747924, 19.160146155970125, 18.430320567006447, 18.744002504926357]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnames.append('CNN2D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test.append(np.array([20.998323330681167, 19.234475326514044, 18.502516721637832, 18.211856287639307, 16.800838330295846, 20.60939168987153, 20.9860453177409, 19.418558315224928, 18.131871812411365, 19.555813843401406]))\n",
    "modelnames.append('CNN1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test.append(np.array([18.661109434586884, 17.4749167644212, 16.328090963137054, 18.26126620806615, 16.439259683040785, 18.517395004384976, 17.763836526777567, 16.69404935545286, 16.896091157174286, 16.87094464406945]))\n",
    "modelnames.append('CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test.append(np.array([19.174632851347162, 14.965517455312737, 24.815246362103796, 14.69731472868515, 15.458120581318491, 26.58457925028661, 17.42879313870755, 19.904137526577433, 15.207624142549776, 14.638524536351927]))\n",
    "modelnames.append('LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sig = [[28.65432678, 27.33126691, 32.05417722, 26.68404638, 27.20298043,\n",
    "        34.19808939, 47.19218419, 28.04451459, 36.88454725, 57.25105967],\n",
    "[22.91231799, 20.87124175, 24.88385949, 16.62592638, 17.30676079,\n",
    "        27.38186206, 42.44519322, 21.06660697, 32.39765622, 39.0779806 ],\n",
    "[25.93480661, 22.51155399, 27.13089021, 21.71908598, 19.72367763,\n",
    "        30.67499452, 40.91537458, 21.51829287, 34.05657651, 41.19434126],\n",
    "[25.35984617, 23.7318953 , 25.73767935, 18.88889724, 22.45273873,\n",
    "        29.24297504, 44.59392753, 22.74959161, 34.69550291, 41.52428139],\n",
    "[22.9676217 , 21.06257806, 24.23064445, 16.80321115, 16.97869103,\n",
    "        27.55799536, 42.19653324, 20.72229717, 32.58228819, 39.20836571],\n",
    "[24.28287418, 21.80293   , 22.19905195, 16.61266033, 17.25766192,\n",
    "        26.27257479, 47.25850793, 22.18165508, 33.67434825, 42.93492414],\n",
    "[23.85962672, 20.86479869, 24.39581339, 17.68919607, 18.09929648,\n",
    "        27.95269707, 42.26654614, 21.65914963, 33.22886124, 39.55790887],\n",
    " [24.27781282, 21.74906995, 25.6492858 , 18.71238073, 19.49997929,\n",
    "        28.18585657, 43.48910747, 22.01955238, 32.83176996, 39.08202969],\n",
    "[18.01777016, 19.08547714, 18.61810288, 17.61940315, 17.46961741,\n",
    "        18.34671841, 17.44214568, 19.16014616, 18.43032057, 18.7440025 ],\n",
    "[20.998323330681167, 19.234475326514044, 18.502516721637832, 18.211856287639307, 16.800838330295846,\n",
    " 20.60939168987153, 20.9860453177409, 19.418558315224928, 18.131871812411365, 19.555813843401406],\n",
    "[18.661109434586884, 17.4749167644212, 16.328090963137054, 18.26126620806615, 16.439259683040785,\n",
    " 18.517395004384976, 17.763836526777567, 16.69404935545286, 16.896091157174286, 16.87094464406945],\n",
    "[19.174632851347162, 14.965517455312737, 24.815246362103796, 14.69731472868515, 15.458120581318491,\n",
    " 26.58457925028661, 17.42879313870755, 19.904137526577433, 15.207624142549776, 14.638524536351927],\n",
    "[14.253180583572306, 14.214632431174541, 15.24421802136218, 14.607750474139724, 13.983064409189407,\n",
    " 14.489753037532221, 13.661561807233946, 15.069159143216966, 14.689767829931357, 14.152714450603238]]\n",
    "\n",
    "modelnames = ['SGD',\n",
    " 'ExtraTrees',\n",
    " 'AdaBoost',\n",
    " 'Bagging',\n",
    " 'RandomForest',\n",
    " 'SVR',\n",
    " 'GradientBoosting',\n",
    " 'KNN',\n",
    " 'CNN2D',\n",
    " 'CNN1D',\n",
    " 'CNN',\n",
    " 'LSTM',\n",
    " 'GRU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure()\n",
    "sns.boxplot(data=results_sig)\n",
    "plt.xticks(plt.xticks()[0], modelnames)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "fig.savefig('boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "import numpy\n",
    "p = numpy.zeros((len(results_sig),len(results_sig)))\n",
    "s = numpy.zeros((len(results_sig),len(results_sig)))\n",
    "\n",
    "for i in range(len(results_sig)):\n",
    "    for j in range(len(results_sig)):\n",
    "        s[i][j], p[i][j] = mannwhitneyu(results_sig[i], results_sig[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_letters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(p, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "model_inv = modelnames[::-1]\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(p*100, mask=mask,\n",
    "            square=True, linewidths=.5,annot=True, cbar_kws={\"shrink\": .5}, ax=ax, cmap='OrRd')\n",
    "plt.xticks(plt.xticks()[0], modelnames)\n",
    "plt.yticks(plt.yticks()[0], model_inv)\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_val_loss = [3031.7217674082367,\n",
    " 2924.329375917949,\n",
    " 2529.156398353663,\n",
    " 2457.075932837938,\n",
    " 2903.6382146952105,\n",
    " 2230.677318815201,\n",
    " 1928.446299728082,\n",
    " 1994.0078922626383,\n",
    " 2220.6305168783315,\n",
    " 1676.6130244283179,\n",
    " 1801.8468650117213,\n",
    " 1922.9241259871155,\n",
    " 1633.829518982072,\n",
    " 1715.6588729806497,\n",
    " 1634.930201228784,\n",
    " 1782.76660640656,\n",
    " 1652.0217194113873,\n",
    " 1752.3951839568124,\n",
    " 1768.2913672734821,\n",
    " 1817.443348927833,\n",
    " 2009.4655160374111,\n",
    " 1873.0356189874835,\n",
    " 1769.81899948185,\n",
    " 2240.4773564457623,\n",
    " 1820.0706298681073,\n",
    " 2209.345026809342,\n",
    " 2033.1465486652996,\n",
    " 1921.4363754593055,\n",
    " 1899.8828418573826,\n",
    " 1972.224581357303,\n",
    " 2358.5931931753007,\n",
    " 2020.0059627026928,\n",
    " 2319.431614374087,\n",
    " 2267.0938544932947,\n",
    " 1718.6965160013056,\n",
    " 2066.163143975394,\n",
    " 2273.4551649147693,\n",
    " 2037.6107264019195,\n",
    " 1904.3933727584458,\n",
    " 2208.59751421524,\n",
    " 1939.0497927438646,\n",
    " 1957.672191446871,\n",
    " 2219.176108365697,\n",
    " 2082.099818543242,\n",
    " 1976.6663236542354,\n",
    " 2248.774754681014,\n",
    " 2019.2041749759596,\n",
    " 2153.85292485728,\n",
    " 2262.051716893168,\n",
    " 2471.1514413751443,\n",
    " 2227.6516234642254,\n",
    " 2235.7627665007194,\n",
    " 2179.578035099436,\n",
    " 2476.6357464087523,\n",
    " 2241.5153351630215,\n",
    " 2442.206079392206,\n",
    " 2494.067430554604,\n",
    " 2367.9417443783645,\n",
    " 2313.3071518549846,\n",
    " 2390.2178504667045,\n",
    " 2546.9236205916286,\n",
    " 2622.942600224294,\n",
    " 3448.0582908405468,\n",
    " 2636.9137494569463,\n",
    " 2429.2870739355108,\n",
    " 2674.043030970221,\n",
    " 3006.8156724830333,\n",
    " 2983.0378965780037,\n",
    " 2688.577234873696,\n",
    " 2609.518538888079,\n",
    " 3061.8731124514625,\n",
    " 2785.98852979353,\n",
    " 2962.6271328136763,\n",
    " 2439.2875856499013,\n",
    " 2876.2468739810174,\n",
    " 3362.6285262464667,\n",
    " 2896.4771418495784,\n",
    " 2992.5780754175858,\n",
    " 2899.7267058149755,\n",
    " 2694.272812261603,\n",
    " 2866.649811448424,\n",
    " 2821.8350234821,\n",
    " 2969.1428545954004,\n",
    " 3399.523882686416,\n",
    " 3015.7862185350623,\n",
    " 3166.9297749525836,\n",
    " 2940.424503239915,\n",
    " 3038.812027133241,\n",
    " 3124.7072823626113,\n",
    " 3137.3042251517713,\n",
    " 2940.269537949508,\n",
    " 3165.4724820368415,\n",
    " 3023.844465952071,\n",
    " 3112.7998968197917,\n",
    " 3193.2929540448176,\n",
    " 3295.7612485993745,\n",
    " 3092.3861556928987,\n",
    " 3166.823697520492,\n",
    " 3183.712142377754,\n",
    " 3105.19446992766]\n",
    "\n",
    "overfit_loss = [2117.854875908492,\n",
    " 1318.594980423667,\n",
    " 1242.2128267009925,\n",
    " 1223.8522811969467,\n",
    " 1147.1509638561706,\n",
    " 1103.7239519363166,\n",
    " 1072.40451032687,\n",
    " 1050.7910454059404,\n",
    " 1008.9502477388027,\n",
    " 1006.4736362591187,\n",
    " 981.9634689799387,\n",
    " 940.719219886461,\n",
    " 947.4961189072396,\n",
    " 897.4693248813933,\n",
    " 895.0156377824935,\n",
    " 860.535063699054,\n",
    " 890.0899875655534,\n",
    " 854.7538881744848,\n",
    " 867.5033236021745,\n",
    " 855.3406971651191,\n",
    " 847.0040216809554,\n",
    " 839.1765548197333,\n",
    " 834.4820997738587,\n",
    " 831.8846443778755,\n",
    " 828.5163069766088,\n",
    " 831.0652472071156,\n",
    " 835.5238137584466,\n",
    " 795.750401384913,\n",
    " 796.1582904752444,\n",
    " 808.1163971818537,\n",
    " 788.8935312958831,\n",
    " 787.8450201559497,\n",
    " 788.0843459757002,\n",
    " 788.2548550087495,\n",
    " 829.7563299384753,\n",
    " 780.7672449992947,\n",
    " 778.7846778046921,\n",
    " 770.6499253468529,\n",
    " 807.2972669759515,\n",
    " 782.1444923062852,\n",
    " 778.896525807512,\n",
    " 773.1118810957454,\n",
    " 738.4298138401192,\n",
    " 756.3484916915407,\n",
    " 729.5380932384849,\n",
    " 736.7773662030287,\n",
    " 744.1571496405853,\n",
    " 720.4840751364738,\n",
    " 726.4776419340689,\n",
    " 705.5301465434599,\n",
    " 705.4494199694507,\n",
    " 690.8033095910538,\n",
    " 672.7098932706799,\n",
    " 694.9502425650278,\n",
    " 706.7397712817631,\n",
    " 666.8579170456409,\n",
    " 677.7280229277698,\n",
    " 650.6826516306077,\n",
    " 632.5243918864317,\n",
    " 667.3959013559706,\n",
    " 666.7098953324966,\n",
    " 620.7452211822973,\n",
    " 614.494432064313,\n",
    " 631.6037904793834,\n",
    " 625.8404595599911,\n",
    " 630.3150801211154,\n",
    " 596.4697085331449,\n",
    " 581.6061258617162,\n",
    " 574.7508498127102,\n",
    " 575.2277907176002,\n",
    " 576.5832696401262,\n",
    " 573.7285713036645,\n",
    " 540.4749221787333,\n",
    " 594.2843494796344,\n",
    " 531.4948174355274,\n",
    " 534.8225302568507,\n",
    " 511.78813137439835,\n",
    " 525.400460178613,\n",
    " 515.8699818654,\n",
    " 518.6337601855278,\n",
    " 514.9518282577718,\n",
    " 515.6517586864641,\n",
    " 512.1800023963233,\n",
    " 489.89661498781095,\n",
    " 508.75588046053656,\n",
    " 482.40475688512873,\n",
    " 460.3336007174783,\n",
    " 457.1335752432728,\n",
    " 474.649447455466,\n",
    " 466.7470601649773,\n",
    " 450.12463765689193,\n",
    " 448.7378544251169,\n",
    " 441.0108043458847,\n",
    " 443.4844607538752,\n",
    " 424.4346864704765,\n",
    " 433.9024677821156,\n",
    " 418.8324143843742,\n",
    " 442.00669943062474,\n",
    " 411.06947403689776,\n",
    " 408.27150801857397]\n",
    "\n",
    "normal_val_loss = [2638.592434076495,\n",
    " 2872.791335938469,\n",
    " 2576.4507605451035,\n",
    " 2625.184218183937,\n",
    " 3042.2874636574397,\n",
    " 2442.5371465488356,\n",
    " 2522.1581174024377,\n",
    " 2681.4429111653717,\n",
    " 2877.437149636059,\n",
    " 1982.682385399228,\n",
    " 3060.2699389295512,\n",
    " 2795.375446181178,\n",
    " 3158.119543495092,\n",
    " 2743.863231131279,\n",
    " 2974.575469624699,\n",
    " 2709.1055830784667,\n",
    " 2431.0303830084076,\n",
    " 2262.3382767830844,\n",
    " 2578.5001589803196,\n",
    " 2754.7460016004084,\n",
    " 3136.859801874139,\n",
    " 2092.9638773773263,\n",
    " 3088.8971823521483,\n",
    " 3096.4523758228675,\n",
    " 2697.2636127255673,\n",
    " 2820.7369060386604,\n",
    " 2716.984460869614,\n",
    " 2504.8531265604793,\n",
    " 2244.073823440102,\n",
    " 2335.029008662079,\n",
    " 3083.178676458173,\n",
    " 2683.7842058627243,\n",
    " 3116.9801504087554,\n",
    " 2665.9886563186474,\n",
    " 2991.282171902473,\n",
    " 2598.231815995543,\n",
    " 2553.607684250051,\n",
    " 2494.7713689133693,\n",
    " 2148.32272644216,\n",
    " 2695.826736086891,\n",
    " 3214.99888620355,\n",
    " 3069.9916465655474,\n",
    " 3046.0417006442876,\n",
    " 2770.57907898572,\n",
    " 2790.1888633260924,\n",
    " 2907.615921297311,\n",
    " 3123.0926930953046,\n",
    " 2668.556151392238,\n",
    " 3224.2357899845324,\n",
    " 3338.3759276720943,\n",
    " 2511.3504787972724,\n",
    " 2254.5436211583838,\n",
    " 2667.3054845554757,\n",
    " 2544.772331237793,\n",
    " 3506.1539164605865,\n",
    " 2524.099858030981,\n",
    " 2888.4855573139494,\n",
    " 2311.832234475618,\n",
    " 3083.284755680837,\n",
    " 2145.8216943373213,\n",
    " 2371.269276685996,\n",
    " 2305.823315955614,\n",
    " 2747.6176979168745,\n",
    " 2544.333734698306,\n",
    " 2816.2784413880504,\n",
    " 2188.012582220999,\n",
    " 2524.493170653882,\n",
    " 2889.3734792419573,\n",
    " 2396.0392248452117,\n",
    " 2616.818992286042,\n",
    " 2648.8355990559066,\n",
    " 2514.9047139053173,\n",
    " 2893.865869863774,\n",
    " 2907.057890712539,\n",
    " 2731.25567453951,\n",
    " 2524.621893417808,\n",
    " 2140.6801705738853,\n",
    " 2505.2862458348004,\n",
    " 2396.5942409022323,\n",
    " 2580.6899403855373,\n",
    " 2239.7707187367137,\n",
    " 2548.967884963332,\n",
    " 2545.521503336035,\n",
    " 3018.5936791902227,\n",
    " 3127.8285597370864,\n",
    " 2643.5994356462475,\n",
    " 2723.715581033235,\n",
    " 2944.354026431129,\n",
    " 2729.128236454901,\n",
    " 2474.6189677785583,\n",
    " 2879.9978223874186,\n",
    " 2892.010249935851,\n",
    " 2872.3816638263174,\n",
    " 2785.5337157390013,\n",
    " 2812.6046111178234,\n",
    " 2594.704290480841,\n",
    " 2595.821296838946,\n",
    " 2746.867856170585,\n",
    " 2747.966006151403,\n",
    " 2771.721996956131]\n",
    "\n",
    "normal_loss = [2589.9523749526707,\n",
    " 1357.6303935121587,\n",
    " 1295.7775770276212,\n",
    " 1263.5625174408142,\n",
    " 1223.2883251236105,\n",
    " 1185.4622356366472,\n",
    " 1144.3526121338953,\n",
    " 1117.6809310215876,\n",
    " 1094.793273575734,\n",
    " 1062.1133095615114,\n",
    " 1050.5481429479596,\n",
    " 1031.60639882546,\n",
    " 1025.5080043758826,\n",
    " 998.800037426587,\n",
    " 980.7274081525336,\n",
    " 973.193023883591,\n",
    " 986.3515402046849,\n",
    " 966.5710233497343,\n",
    " 971.2183342593044,\n",
    " 958.2290499547693,\n",
    " 954.4207491327445,\n",
    " 941.1572293782644,\n",
    " 946.586421796097,\n",
    " 950.9569667989983,\n",
    " 937.7930805689297,\n",
    " 938.9171452619947,\n",
    " 925.8643353383422,\n",
    " 921.8691014427916,\n",
    " 919.5663294934923,\n",
    " 917.376164232046,\n",
    " 914.4926228241064,\n",
    " 896.6952513956037,\n",
    " 906.2257368193913,\n",
    " 895.5873120431075,\n",
    " 894.234665496878,\n",
    " 888.9109127443529,\n",
    " 899.2524265350132,\n",
    " 876.7222555882615,\n",
    " 885.1137196976048,\n",
    " 889.7987210259378,\n",
    " 875.8393855728108,\n",
    " 881.5041409701234,\n",
    " 867.3140119116375,\n",
    " 870.8339095879887,\n",
    " 855.6559508019482,\n",
    " 864.8111066582028,\n",
    " 841.153224999643,\n",
    " 838.9718882079355,\n",
    " 823.4259683637017,\n",
    " 819.1815524515677,\n",
    " 802.833929607997,\n",
    " 789.152630134785,\n",
    " 776.8046310731577,\n",
    " 789.2295117439842,\n",
    " 771.0726751148524,\n",
    " 750.0201712594093,\n",
    " 760.453717503001,\n",
    " 749.8950163038916,\n",
    " 734.3403366395639,\n",
    " 733.0620164655442,\n",
    " 708.5132822916789,\n",
    " 720.9310152598738,\n",
    " 707.4754399870432,\n",
    " 709.2067429880387,\n",
    " 695.5209502106377,\n",
    " 708.4961062939998,\n",
    " 684.8256047408056,\n",
    " 672.8181892982118,\n",
    " 677.9770122837493,\n",
    " 673.9493581149532,\n",
    " 655.5554489450208,\n",
    " 649.7897549357119,\n",
    " 651.4393991638749,\n",
    " 650.3464324618435,\n",
    " 633.510986093478,\n",
    " 631.3506648943045,\n",
    " 616.1067069093259,\n",
    " 629.2077481255471,\n",
    " 619.4336482496593,\n",
    " 606.3929168322275,\n",
    " 603.2005095875855,\n",
    " 583.479366809049,\n",
    " 587.8350927398945,\n",
    " 591.6567520831118,\n",
    " 589.8380269087683,\n",
    " 566.2965028113331,\n",
    " 558.5184320825,\n",
    " 554.8317355562671,\n",
    " 548.3461182117612,\n",
    " 545.3387662161874,\n",
    " 537.7250181609113,\n",
    " 542.8820531918059,\n",
    " 534.5345085222419,\n",
    " 531.1407003428554,\n",
    " 526.56610185894,\n",
    " 525.9916142996027,\n",
    " 519.320765918855,\n",
    " 507.53622640974095,\n",
    " 508.82544293051717,\n",
    " 519.6103655797755]\n",
    "\n",
    "df_normal = pd.DataFrame({'Loss':normal_loss,'Overfit Loss':overfit_loss,\n",
    "                          'Validation Loss': normal_val_loss, 'Overfit Validation Loss': overfit_val_loss})\n",
    "df_normal = df_normal.rolling(10).sum()\n",
    "df_overfit = pd.DataFrame({'Loss':overfit_loss, 'Validation Loss': overfit_val_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "sns.set(style=\"white\",rc={\"lines.linewidth\": 3.5})\n",
    "palette = sns.color_palette(\"RdBu\", 4)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "ax = sns.lineplot(data=df_normal, palette=palette)\n",
    "#ax = sns.lineplot(data=df_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
